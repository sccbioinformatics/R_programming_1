--- 
title: "An introduction to R programming"
author: "Shamit Soneji"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
#output: bookdown::gitbook
#output:
#  bookdown::html_book:
#    theme: flatly
#    code_folding: hide
output:
  html_document:
    code_folding: show

documentclass: book
bibliography: [book.bib, packages.bib]
biblio-style: apalike
link-citations: yes
github-repo: rstudio/bookdown-demo
description: "This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook."
---

# Introduction

The purpose of this course is to teach you the basics of the R language and give you the confidence to tackle larger projects using the language. *Importantly, we want to get you thinking like a programmer*. This doesn't mean that by the end of the course you will know R fully, but you will know enough so you can go online and look for the help you need to complete most tasks.

## Practice makes perfect

Programming is like any skill, the more you practice the better you get. ***It's really important that you keep using what you have learned after the course is completed*** otherwise there is a good chance you will forget everything and you'll be back to square one.

## Why Use R?
R is a programming language with a focus on mathematics and statistics, but R can be used for a wide variety of applications given the flexibility of the language. R is also free, and available for all operating systems. Given the richness of the language and no cost to use it, bioinformaticians have used R for more than 20 years as the platform for which which to develop packages to solve bioinformatics problems.

The [BioConductor Project](https://www.bioconductor.org/) is a repository for bioinformatics tools which continues to grow, and hosts packages such as DESeq2 which you may have heard of. Some other popular packages such as Seurat aren't actually hosted by Bioconductor, but in the main R package repository. We'll cover package installation later later.

## What other languages do bioinformaticians use?

The Python language has been rocketing in popularity for the past few years, particularly among data scientists whi make use of the AI/ML tools such as Tensorflow and PyTorch. Scanpy is a very popular package for single-cell analysis. For very computationally intensive tasks (e.g sequence alignment), languages such as C/C++/Rust are more commonly used, but these are far more difficult to learn.

## How will this course work?
We're going to take a differnt approach to this course, so it's somewhat experimental at this point. You will be taught the basics of the R lauguage doing small exercises along the way. However, we will finish by you undertaking a project which will push you quite hard. The aim is that by tacking a more difficult problem will consolidate what you have learnt, and learn more by having to look up solutions to the problems you will likely face.

## Getting R and RStudio

Point your browser to http://cran.r-project.org/ to download and install the latest version of R. For these tutorials we are also going to use [RStudio](http://www.rstudio.com/) which is an advanced development environment for R which includes a window for an editor, console, and plotting window. You will see what this means later.



```{r include=FALSE}
# automatically create a bib database for R packages
knitr::write_bib(c(
  .packages(), 'bookdown', 'knitr', 'rmarkdown'
), 'packages.bib')
```

<!--chapter:end:index.Rmd-->

# RStudio

Open up RStudio, and it will look something like this:

```{r, out.width='90%', fig.align='center',echo=FALSE}
knitr::include_graphics(rep("images/rstudio.png"))
```

The different parts are:

1. The code editor. This is where you write code.
2. The R console. This is the R environment where R code is executed.
3. Workspace. The objects you create along the way will be listed here.
4. Plots and files. Plots will render here, and files can be browsed in the "Files" pane.

Before we start, we need to do a little prep.

1. On your computer, make a folder called "Rcourse1".

We then set the working directroy to this folder, so

2. In RStudio go to Session > Set Working Directory > Choose Directory and find the "Rcourse1" folder and select it.

RStudio will now be looking for files in this folder, and any saved plots will be put here unless stated otherwise.

Now, go to File > New File > R Script

A new empty script will open up in the top left window. Go to File > Save and give it a name. It will them be saved to you current working directory. You should see your file being added to the list in the Plot and Files pane.

Now that we've done our prep, let do some R.


<!--chapter:end:01-Rstudio.Rmd-->

# The Basics {#thebasics}

We'll now look at some basic operations. The code should be copied into your R script as we go along.

## Assigning a variable.

Into your script copy/type the following line:

```{r}
x <- c(1,2,3,4,5,6,7,8,9,10)
```

This will make a **vector** of values from 1 to 10, and put them into a variable called `x`.

Execute the code by hitting the "Run" button at the top-right of the script window. You will see this line appear in the R console below.

To view the contents of the object you have just created, just type `x` in the **console** and hit return:

```{r}
x
```

The contents of x are now printed out.

Now is a good time to learn about commenting and documenting code. This is free text you put into your scripts that tell the reader whats going on, and to remind your future self of what you did. Comments are put in using ```#```, so for example:

```{r}
x <- c(1,2,3,4,5,6,7,8,9,10) # This is a comment.
```

Anything after a `#` will be ignored. You can run the code again to check.

Rather than typing in the value 1 to 10, there is a much simpler way to create the same vector using `:`

```{r}
x <- 1:10
x
```
Much better! Using a colon will always do increments of 1, and it's also bidirectional:

```{r}
y <- 5:-5
y
```

Another way of creating a sequence of numbers is to use the `seq` function. To learn how this function works, issue the command `help(seq)`. In R you can get a manual for any function using the `help()` command. To generate a vector of numbers from 1 to 100 in steps of 10 we need:

```{r}
a <- seq(0,100,by=10)
a
```

***Exercise:*** Generate a vector called 'b' ranging from 3 to 987 where the length of the vector is 53 entries long.
Done? Check the length of the vector you have just made by issuing `length(b)`.

```{r class.source = 'fold-hide',results=F}
a <- seq(3,978,length=53)
a
```

A note about assigning things to variable names. I use ```<-```, but you can also use ```=``` too. So

```{r}
g <- 1:5
g
```

Is the same as:
```{r}
g = 1:5
g
```

We can also make a new vector `d` using a vector `c`: 
```{r}
c <- 1:50 #make a vector c ranging from 1:50
d <- 1/c  #make a vector d by dividing 1 by c
d
```

## Basic plotting

Lets use this vector `d` and plot them:

```{r fig.width=5, fig.height=4}
plot(d)
```

Note the way the axes are labelled in the plot function.

***Exercise:*** Call `help(plot)` in the console and read about the other plot options available. Produce the same plot as above, but this time as a **line** which is coloured **red**. Also, label the axes $c$ and $d$ and give the plot a title.

```{r class.source = 'fold-hide',results=T,fig.width=5, fig.height=4}
plot(d,ty="l",col="red",xlab="c",ylab="d",main="My first plot")
```

This plot was done using **base** R. This means we used the plotting functions native, or built-in to the R language. Plotting has been vamped up a lot in R since ggplot was introduced some time ago, the aim here to make plotting more customisable. Lets try the same plot but using ggplot. First, install it:

```{r,eval=FALSE}
install.packages(ggplot2) #you only have to do this once.
```

Now call the ggplot library:

```{r}
library(ggplot2)
```

The first thing we need to do is make a **data.frame** of the data by doing:
```{r}
df <- data.frame(c=c,d=d)
```

This makes a table. You can see the first few lines by doing:
```{r}
df[1:5,]
```
Lets make the plot:
```{r fig.width=5, fig.height=4}
ggplot(data=df, aes(x=c, y=d)) +geom_line()
```

We can even add the points:
```{r fig.width=5, fig.height=4}
ggplot(data=df, aes(x=c, y=d)) +geom_line()+geom_point()
```

and change the colour of each:
```{r fig.width=5, fig.height=4}
ggplot(data=df, aes(x=c, y=d)) +geom_line(color="red")+geom_point(color="green")
```

So ggplot is all about *layering* information onto plots, and this makes it very customisable. It definitely has a steeper learning curve, but worth it if you produce lots of plots on a day-to-day. If you're struggling with the idea, use this analogy of ggplots as a cake (Tanya Shapiro (\@tanya_shapiro), Twitter):

```{r, out.width='60%', fig.align='center',echo=FALSE}
knitr::include_graphics(rep("images/ggplot_cake.png"))
```

Back to vectors, we can also do maths on them:

```{r}
mean(d) # calculate the mean of the vector
sd(d) # the standard deviation
```




<!--chapter:end:02-The-Basics.Rmd-->

# Matricies

Matricies are the most common data format bioinformaticians work with (microarray/RNAseq data for example). Lets make one:

```{r}
m <- matrix(0,ncol=5,nrow=10)
m
```
This will create a matrix filled with zeros. To transpose (flip) the matrix we use `t()` (this will be important later!)

```{r}
tposed.m <- t(m)
tposed.m
```

We can also add names to the row and columns:

```{r}
rownames(m) <- LETTERS[1:10]
colnames(m) <- c("cat","dog","pig","cow","chicken")
m
```


## Subsetting

Lets make a matrix (and a vector) containing integer values so we can take a look at how subsetting work in R:
```{r}
v <- 1:10
m <- t(matrix(1:50,ncol=10,nrow=5))
rownames(m) <- LETTERS[1:10]
colnames(m) <- c("cat","dog","pig","cow","chicken")
m
```
We can access individual elements using square brackets `[]`. Here are some examples:

```{r}
v[c(7,1,5)] #access elements 7 1 and 5 of the vector
m[1,] # access the first row of the matrix
m[,3] # the 3rd column
m[8,2] # the value in the 8th row and 2nd column
m[3:7,4] # the 3rd to 7th row of the 4th column
```

Note the `c(7,1,5)` where we subset vector `v`. `c` means *combine* and it allows element in the `()` to be collected into a single vector.

We can also address elements using the column and row names:

```{r}
m["B",] # gets the row labelled B
m["B","cow"]
m[c("F","J"),c("chicken","cat","pig")]
```


We often need to collect vectors and assemble them into a matrix. This can be done using the `rbind` (row) and `cbind` (column) functions:

```{r}
v1 <- 1:10
v2 <- 101:110
rbound.mat <-rbind(v1,v2)
cbound.mat <- cbind(v1,v2)
rbound.mat
cbound.mat
```

We will do a lot more work with matrices later, particularly mathematical operations.

<!--chapter:end:03-Matricies.Rmd-->

# Lists

So far we have talked about vectors and matrices. Often we want to collect these things and put them into one object under a single variable. For example:
```{r}
alpha <- LETTERS[1:8]
mat <- matrix(rnorm(40),nrow=8)
listex1  <- list(char=alpha,nums=mat)
```

You can see that each item is given a name 'char' 'numb'  before it is put into the list. Each element can now be accessed via `$`:
```{r}
listex1$char
listex1$nums
listex1$nums[1,] # the matrix within the list issubsetted as before
```
Another way of doing the above is:
```{r}
listex1[[1]] # note the double square brackets
listex1[[2]]
listex1[[2]][1,]
```

Lists are ok, but they can become like the wild-west where things are thrown in with little organisation. They are fine for small things, but big data shouldn't be stored in them, or become the basis for a large project. You will see why later.

<!--chapter:end:04-Lists.Rmd-->

# Data Frames

Data frames can be thought of as a list where each column is of the same length. It allows you to mix different classes (characters,numerics) in the same container. For example, the iris datra which comes with R:

```{r}
data(iris)
iris[sample(1:nrow(iris),10),] # show 10 random rows.
```

You see the first few column are numeric, and the last character strings. Data frames are the primary input into things like tidyverse etc, and can be adressed by their names just as you wopuld in a list:

```{r}
iris$Sepal.Length
plot(iris$Sepal.Length,iris$Sepal.Width)

ggplot(iris, aes(x=Sepal.Length, y=Sepal.Width,color=Species)) + geom_point()

```




<!--chapter:end:05-DataFrames.Rmd-->

# Reading and writing files.

You have to get the data into R first before you can analyse it (this helps a lot). R has many useful functions to do this, so now we can take our first look at some expression data. Download this file (http://bone.bmc.lu.se/Public/Mouse_HSPC_reduced.txt) and save it to your current working directory.

***Exercise:*** Open the file in Excel or something to see how it looks, and then call `help(read.delim)` in your console. Try to work out how the file you are looking at could be read into R using this function.

This is how I would do it:

```{r,class.source = 'fold-hide',results=F}
hspc.data <- read.delim("Mouse_HSPC_reduced.txt",header=T,row.name=1,sep="\t")
```
We can now look at a few aspects of the data:

```{r}
colnames(hspc.data) # view the column names
nrow(hspc.data) # the number of rows in the dataset
ncol(hspc.data) # number of columns
dim(hspc.data) # number of rows and columns together
colnames(hspc.data) #output the columns headers
```

***Exercise:*** Using subsetting we learnt about earlier, split this data matrix into three parts called `lthsc`, `mep` and `gmp` to separate the cell types shown in the headings. For this look at the help page for a function called `grep`.

```{r,class.source = 'fold-hide',results=F}
lthsc <- hspc.data[,grep("LTHSC",colnames(hspc.data))]
mep <- hspc.data[,grep("MEP",colnames(hspc.data))]
gmp <- hspc.data[,grep("GMP",colnames(hspc.data))]
```

To write a table use the `write.table` function:
```{r}
write.table(lthsc,"LTHSC_data.txt",row.names=T,col.names=NA,sep="\t",quote=F)
```

***Exercise:*** Write out the data for the MEP and GMP data into two files.

The data tables we have now are in the form of a data.frame. Try:

```{r}
class(mep)
```
This can be an awkward format for some operations so we can convert it to a simple matrix first:

```{r}
hspc.data <- as.matrix(hspc.data)
lthsc <- as.matrix(lthsc)
mep <- as.matrix(mep)
gmp <- as.matrix(mep)

```

Try this now:
```{r}
class(mep)
```

<!--chapter:end:06-ReadingWritingFiles.Rmd-->

# Flow control basics

This is where things get more interesting and we start to feel like proper programmers. Now we have these datasets loaded in R, we can use them to learn about flow control and some basic mathematical functions. We are going to do a few things the "long way" so you get the idea of how flow control works, and then we'll look at some shortcuts.

Flow control is how multi-step processes are carried out. In the example below we print out the numbers 1 to 10:

```{r}
for(i in 1:10){
  print(i)
}
```
To translate this code, it simply says for every integer from 1 to 10, print this value to the screen.

***Exercises:*** 
- Using the example above, print the first 10 lines of `lthcs` in a `for` loop.

- Print every **2nd** line of `mep` from lines 1 to 50.

An important point regarding `for` loops is that any processes/calculations occurring within the loop will stay in the loop. If data generated within a loop has to be retained, we need to create a container to "fill up" while the loop is being carried out.

```{r}
vec <- NULL
for(i in 1:10){
  vec <- c(vec,i*10)
}
```
The container `vec` is initialised outside the loop, and then populated by concatenating to it after every iteration of the loop.

***Exercise:*** Initialise an empty container, and for `gmp`, calculate the mean of each row (gene), and store the results in the containers you made.

```{r,class.source = 'fold-hide',results=F}

gmp.row.mean <- NULL

for(i in 1:nrow(gmp)){
  gmp.row.mean <- c(gmp.row.mean,mean(gmp[i,]))
}
```

<!--chapter:end:07-FlowControl.Rmd-->

# Functions

Functions and chunks of code that execture several lines of code to perform a task. Once you have a few lines of useful code that you want to apply repeatedly, a function is a nice way to wrap them up so it can be used quickly when needed. lets turn the code you wrote in the exercise earlier into a function where we also calculate the variance for a gene too.

```{r}
calc.mean.and.sd <- function(mat){
  
  mn <- NULL
  vr <- NULL
  
  for(i in 1:nrow(mat)){  
      mn <- c(mn,mean(mat[i,]))
      vr <- c(vr,var(mat[i,]))
    
  }
  res <- list(mns=mn,vars=vr)
  res # the last line in a function is what the function will return
}
```

You can see a loop is started, and the output from each loop is put into variables `mn` and `vr`. These are then put into a list which is was it returned at the end.
By putting this code into a function we can now calculate the means and deviations of any matrix. For example, `gmp`:

```{r}
gmp.mn.sd <- calc.mean.and.sd(gmp) 
```

Functions can also work with built in conditions:

```{r}
animal.maths <- function(value1,value2,animal=c("pig","cow")){
  
  if(animal=="pig"){print(value1/value2)}
  if(animal=="cow"){print(value1*value2)}
  
}
animal.maths(5,5,"pig")
animal.maths(5,5,"cow")

```

The above can be simplified a bit further since there are only two options `pig` and `cow` by using the `else` statement:

```{r}
animal.maths <- function(value1,value2,animal=c("pig","cow")){
  
  if(animal=="pig"){print(value1/value2)}
  else{print(value1*value2)}
  
}
animal.maths(5,5,"pig")
animal.maths(5,5,"cow")

```

In the case above we're only concerned if one of the arguments is `pig`, anything else goes:

```{r}
animal.maths(5,5,"dog")
```


These functions can now be "banked" for use whenever they are needed (probably not `animal.maths` to be fair). *However*, you should avoid using for-loops etc altogether since R has some built in functions that are much quicker and tidier. Lets look at that now.

<!--chapter:end:08-Functions.Rmd-->

# Apply
'apply' is a commonly used function in R to speed up matrix calculation. For example, to calculates means of a matrix we can do this:

```{r}
lthsc.row.mn <- apply(lthsc,1,mean) # means of rows
lthsc.col.mn <- apply(lthsc,2,mean) # means of columns
```
The format for the function is therefore the matrix first, the direction in which you would like to apply the function in the 3rd argument.

 use `apply` to calculate row and column totals and deviations for a yeast dataset of your choosing.

Your own functions can also be used with `apply` when used as the 3rd argument. Example:

```{r}

example.func <- function(v){
  
  val <- (mean(v)*sd(v))/sum(v) ## This is a nonsense operation.
  val
}

ex.apply <- apply(mep,1,example.func)

```

Lets use the apply function to get the top 500 most variable genes in our HSPC dataset:
```{r}
gene.vars <- apply(hspc.data,1,var)
top.var.genes <- names(rev(sort(gene.vars))[1:500])
hspc.var <- hspc.data[top.var.genes,]
```


<!--chapter:end:09-Apply.Rmd-->

# Standardising data

Lets stick with our expression data and cluster it. by doing this we'll learn more of the language, and some of the fundamental maths that runs underneath. Lets take a look at the range of the data, i.e getting the lowest and highest value in the matrix of variable genes we just made.
```{r}
range(hspc.var)
```


For some operations (such as making heatmaps) the data needs to be z-score normalised (scaled) first. When we scale data, each row of gene is standarised so that it's mean=0 and sd=1. Specifically for a gene `g` of the i-th row:

$$Z_i= \frac{g_i-\hat{g}}{\sigma_g}$$

Which means for every row $i$ we subtract from each element $g$ we subract the mean of the row $\hat{g}$ and then divide by the standard deviation of the row $\sigma_g$.

***Exercise:*** write a function called `zscore` which will take a single vector of values and scale them. When you have done this, `apply` this to the `hspc.var` matrix to scale all rows and call it `hspc.zs`.
```{r,class.source = 'fold-hide',results=F}
zscore <- function(v){
  z <- (v-mean(v))/sd(v)
  z
}

hspc.zs <- apply(hspc.var,1,zscore)
```

Now take a look at the first row of the normalised data. Call `nrow` on the matrix. Does it look right? 

```{r}
hspc.zs <- t(apply(hspc.var,1,zscore))
boxplot(hspc.zs,las=2)
# compare to the original data
boxplot(hspc.var,las=2)
```


We can see now the data has been centralised around 0.

***Exercise:*** Do some Googling and see if there is a built in function in R that will zscore rows of data for you. Use it to zscore your data and save the output in `hspc.zs.v2`.

```{r,class.source = 'fold-hide',results=F}

hspc.zs.v2 <- t(apply(hspc.var,1,scale))
hspc.zs.v2[1,]

```

Lets make sure the same thing has been returned by comparing the first row:

```{r}
all.equal(hspc.zs[10,],hspc.zs.v2[10,])
```









<!--chapter:end:10-StandardisingData.Rmd-->

# Clustering

All the steps before have been leading to this, clustering the data and making heatmaps- a staple method in bioinformatics.

Clustering is one of the most common visualisation techniques for genes expression data. Here we will learn how to do some basic histograms/heatmaps and plotting. The first thing  
R has many ways to do this, and many packages have been written specifically for expression data. We are not going to use these for now, but concentrate on the basic underlying functions that do the maths. For example, the `gplots` package uses the `hclust` function which is provided by R. So we will use `hclust` for now.

To use `hclust` we need to provide a distance matrix. This is done using the `dist` function:

```{r}
hspc.dst <- dist(hspc.zs)
```

The we cluster using `hclust`:

```{r}
hspc.hc <- hclust(hspc.dst)
```

Plot the dendrogram:

```{r}
plot(hspc.hc)
```

You'll see form this what we have clustered are the genes. If you want to cluster the cells then you need to transpose the matrix using `t()`:
```{r}
hspc.dst <- dist(t(hspc.zs)) #transpose the matrix here!
hspc.hc <- hclust(hspc.dst)
plot(hspc.hc)
```

We can see this is pretty much useless. It is far to compact and doesn't really tell us anything. What we would like is to make a heatmap where the genes and samples are clusters, and to do this we need to retrieve some information created by `hclust`

Call `names` to see which information is available in the newly created object:

```{r}
names(hspc.hc)
```

What we need here is the component called `order`. We can get this using the `$` assignment.

```{r}
hspc.hc$order
```

This is the order the cells appear in form left to right when you plotted the dendrogram os cells ust before. We use this to reorder the z-scored matrix:

```{r}
hspc.cell.clustered <- hspc.zs[,hspc.hc$order]
```

To make a heatmap of the data call `image`:

```{r}
image(hspc.cell.clustered)
```

Ok, this **doesn't** look like it should! The matrix is the wrong way round, the colours aren't right, and there are no labels. One downside to R is that getting all this done takes time and knowledge of R's plotting capabilities. Thankfully people have already done this and put the code into convenient functions/packages for people to install and use.

***Exercise:*** Install the `pheatmap` package.

To use the functions provided by ggplots we have to load it first:

```{r}
library(pheatmap)
```

We can now use the `pheatmap` function that the package provides:
```{r}
pheatmap(hspc.zs)
```

The pheatmap function uses `hclust` to cluster the genes and cells and reorders the matrix according to both. Lets output this to a file:

```{r}
png("HSPC_heatmap.png",height=4500,width=1500)
pheatmap(hspc.zs)
dev.off()
```
The file is opened, and the plot is then made. The `dev.off()` then closed and finalises the file, i.e nothing more can be written to it.

***Exercise:*** call `help (pheatmap)` and see what options are available. Play with the options to see what they do.

Clustering is pretty pointless if you can't define groups and get to the gene names. First we need to capture the output from `pheatmap` as a variable:

```{r}
hspc.clust <- pheatmap(hspc.zs)
```
Lets take a look at the contents of `hspc.clust`:
```{r}
names(hspc.clust)
```

What we want is the information contained within the hclust object in `tree_row`. We get this by treating it like a list:

```{r}
hspc.clust$tree_row
hspc.clust$tree_row$order #the order of genes in the heatmap for examples.
```

Lets say that we want to split the genes in to 5 clusters groups, we can call the `cutree` function on an `hclust` object to do this:
```{r}
gene.clusters <- cutree(hspc.clust$tree_row,k=5)
gene.clusters[1:20] # shows the results for the first 20 genes.
table(gene.clusters)
barplot(table(gene.clusters))
```

Lets isolate all the genes beloning to cluster 1 using the `which` command:

```{r}
which(gene.clusters==1)
```
We can isolate these rows only from our `hspc.zs` matrix as we did before:

```{r}
hspc.cluster.1 <- hspc.zs[names(which(gene.clusters==1)),]
```

We can now see how these gene behave as a whole using a boxplot:

```{r}
boxplot(hspc.cluster.1,las=2)
```

<!--chapter:end:11-Clustering.Rmd-->

# Efficiency- time is precious.

Something to remember- always- is that comuputer resources such as RAM and disk space should be used wisely. In this was your code will be faster and leaner. Here is a small example where we make a vector from one to 50,000 using a loop:

```{r}
values <- NULL # make an empty container to catch the values

for(i in 1:50000){
  values <- c(values,i)
}

values[1:10]
```

Lets do this again, but this time measure how long it takes using the `system.time` function:

```{r}
values <- NULL # make an empty container to catch the values
system.time(for(i in 1:50000){  values <- c(values,i)})
length(values) # check length
```

Ok, now the same thing again, but this time we will fill a vector rather that growing it:

```{r}
values <- vector("numeric",100000) # make an empty container to catch the values
system.time(for(i in 1:100000){  values[i] <- i})
length(values) #check length
```
**Why, do you think, this was so much faster?**



<!--chapter:end:12-Efficiency.Rmd-->

# Linear models

Fitting a linear model (or linear regression) is also another fairly common thing we tend to do, and actually forms the basis of some of the more famous packages we use such as DESeq2, limma etc. Let's use our expression data to demonstrate this.

In our case we have 3 different samples:

```{r}
colnames(hspc.data)
```
We need to make a vector of *factors* from this info to specify the different groups.

***Exercise:*** Install the `stringr` package and call it in your session.


```{r}
samples <- colnames(hspc.data)
groups <- gsub("\\..*","",samples) # This will make a new vector of names but remove the ".X" leaving just what type each sample belongs to
groups
```

```{r}
lmod <- lm(hspc.data[1,]~ -1+groups)
lmod
```

Lets call `anova` on this:

```{r}
ano <- anova(lmod)
ano
```
As you can see, the groups factor has a significant value meaning it seems this gene is differentially expressed.

***Exercise:*** Take a look at the `ano` object and see how to isolate just the p-value from all this info.

```{r,class.source = 'fold-hide',results=F}
ano$`Pr(>F)`[1]
```


***Exercise:*** Make a function called `do.anova` which takes a vector `v`and a vector `groups`, performs linear modelling and ANOVA and returns *just* the p-value.

```{r}
do.anova <- function(v,groups){
  
  mod <- lm(v~ -1+groups)
  p <- anova(mod)$`Pr(>F)`[1]
  p
}
```

We can now apply this to all of our data:

```{r}
ps <- apply(hspc.data, MARGIN=1, FUN=function(x) do.anova(x,groups) )
p.adj <- p.adjust(ps,"hochberg")
```

Get the top 500 genes:

```{r}
sig.genes <- names(sort(p.adj))[1:500]
```

Heatmap them!

```{r}
library(RColorBrewer)
breaksList = seq(-3, 3, by = 0.2)
hspc.zs.all <- t(apply(hspc.data,1,zscore))
pheatmap(hspc.zs.all[sig.genes,],breaks = breaksList,color = colorRampPalette(rev(brewer.pal(n = 7, name = "RdYlBu")))(length(breaksList)))
```


<!--chapter:end:12-LinearModels.Rmd-->

# Kmeans

We're going to program our first algorithm together! Kmeans clustering is a common way to cluster expression data, and the algorithm is actually pretty simple, and a great start to learning programmatic thinking. The data we'll use comes from yeast where the expression of 256 genes have been measured as a synchronised population go through two divisions. It's a nice, small dataset with clear clusters.

There is a file called ""Spellman_Yeast_Cell_Cycle.tsv". Load it into a variable called `ycc` and convert it to a matrix.

```{r}
ycc <- read.delim("Spellman_Yeast_Cell_Cycle.tsv",row.names=1,header=T,sep="\t")
ycc <- as.matrix(ycc)
```

The data has already been z-scored, so we need to learn how to calculate the Euclidean distance between 2 genes (vector). We do this using the formula:

$$\sqrt{\Sigma{(G_1-G_2)^2}}$$

Write a function called `e.dist` which takes two vectors `v1` and `v2` and calculates the distance between them.

```{r,class.source = 'fold-hide',results=F}
e.dist <- function(v1,v2){
  d <- sqrt(sum((v1-v2)^2))
  d
}
```

The kmeans algorithm needs the user to say how many clusters are being searched for, so in this case we'll say **10**.

1. Define 10 centers randomly, i.e pick 10 genes at random.
2. Calculate the distance between each gene to each of the 10 centroids.
3. Assign each gene to the closest centroid.
4. For each of the 10 clusters, calculate a new centroid.
5. Repeat steps 2,3, and 4 100 times.

We'll now work through this problem together and crowd source a solution.

```{r}
centroids <- ycc[sample(1:256,10,replace=F),]

dists <- matrix(0,nrow=256,ncol=10)

clusters <- NULL

for(rounds in 1:100){

  for(i in 1:256){
  
    for(j in 1:10){
      dists[i,j] <- e.dist(ycc[i,],centroids[j,])
    }
    
  }

  clusters <- apply(dists,1,which.min)

  for(k in 1:10){
    centroids[k,] <- apply(ycc[which(clusters==k),],2,mean)
  }
}
```

***Exercise*** Plot your clusters using base R or ggplots. Dealers choice.

ggplots:
```{r,class.source = 'fold-hide',results=F}
library(reshape2)
ycc.cl <- cbind(as.factor(clusters),ycc)

colnames(ycc.cl)[1] <- c("Cluster")

ycc.df <- data.frame(ID=rownames(ycc.cl), ycc.cl, row.names=NULL)

ytm <- melt(ycc.df,c("ID","Cluster"))

ggplot(ytm,aes(x = variable, y = value,group = ID)) + geom_line()+facet_wrap(~ Cluster, ncol = 3)

```

base R:

```{r,class.source = 'fold-hide',results=F}

par(mfrow=c(3,4))

for(i in 1:10){
  
  ycc.c <- ycc[which(clusters==i),]
  plot(ycc.c[1,],ty="l",ylim=range(ycc.c))
  apply(ycc.c,1,lines)
  
}


```

***Improvements***

1. The code above will do 100 iterations, but what if the algorithm converges after 20? Alter the code so it stops when no further changes are made and help save the planet.
2. Write a function from this code that will take any `data`, number of clusters `K`, and `iterations` as an argument and perform Kmeans clustering. Return a list that contains the cluster assignments and data.
3. Write a function that will plot from the list, a cluster of the user's choice.



<!--chapter:end:13-Kmeans.Rmd-->

# The Final Project

Your final project is going to combine everything you have learned over the last few days to tackle a final project you will do in your own time over the next X weeks. It will be along the same lines the Kmeans clustering we just did, but this time we're going to cluster the data using the Metropolis-Hastings algorithm. This is a simulated annealing process, so we need to learn how that works first.

## Optimisation problems

Programming an optimisation problem is a great way of learning how to code. In this case we are going to tackle a minimisation problem. We can think of well clustered data having low energy, in that, each cluster is tight and has little within cluster variance. If we calculate the variance *within* each cluster, and sum over all clusters, we get the total variance (energy) of the system. Lets go back to the equation we know that measures the distance between two genes:

$$d=\sqrt{\Sigma{(G_1-G_2)^2}}$$

To measure the variance of a cluster $K$ we apply the following:

$$ V_K= \frac{1}{t}\Sigma(g-\hat{g})^2 $$
where $t$ is time, and $g$ is a gene. To get the total variance of all clusters, we simply sum and then divide by how many clusters there are:

$$ V_{tot} = \frac{\Sigma V_K}{K}$$

For a well clustered data, $V_{tot}$ should be as **small** as possible. Lets say we have 1000 genes, and we want to partition them into 10 clusters. The number of combinations is too high for us to try each one to brute force a true $V_{tot}$. This is why we use a *heuristic* algorithm to get us as close to the solution as possible in a smaller amount of time.

If we tried to visualise the energy landscape we can imagine it might look something like this:

```{r, out.width='60%', fig.align='center',echo=FALSE}
knitr::include_graphics(rep("images/EnergyLandscape.png"))
```

Lets go through the process of the algorithm. To do this you need 4 parameters:

1. The temperature of the system $T$
2. Cooling factor $c$
3. Number of clusters $K$
4. How many iterations to perform $I$.

Algorithm goes:

&nbsp;&nbsp;&nbsp;&nbsp;Randomly assign each gene to each of your K clusters.

for each iteration $I$ {

&nbsp;&nbsp;&nbsp;&nbsp;Calculate $V_{tot}$. Call this $V_{old}$
    
&nbsp;&nbsp;&nbsp;&nbsp;Randomly select a gene and assign it to another cluster.
  
&nbsp;&nbsp;&nbsp;&nbsp;Calculate $V_{new}$
    
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if($V_{new}$ < $V_{old}$) {accept the move}
    
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if($V_{new} > V_{old})$ {if($e^{-\frac{  V_{new}-V_{old}}{T}} > R(0,1)$) {accept the move} }
        
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;else{reject the move}
  
&nbsp;&nbsp;&nbsp;&nbsp;Set a new $T$ by doing $T=T \times c$
}

Done

***Things to do***

1. Code this algorithm using the same yeast timecourse data.
2. Put this algorithm into a function.
3. When running the function, make sure the starting $V_{start}$ and final $V_{final}$ are printed to the screen.

***Tip***

Try and break the problem up into functions which can be called when needed. It will be easier to write the main algorithm.

***Why this exercise is a good one***

By tackling a more difficult problem the idea is that you will dig deeper into the language and really understand how things work in the background of the functions you use in packages such as Seurat etc.

***Are there libraries in R to do this?***
Yes there are, but you won't learn anything using them which is why we are coding this "by hand".

***A little inspiration***

Before you start, read [this](https://www.newyorker.com/magazine/2018/12/10/the-friendship-that-made-google-huge), and then watch [this](https://youtu.be/USC6c9Dtak8).

***To make it tasty....***

We'll reconvene in X weeks and we'll run each of your implementations on the same laptop and see who a) can get to the solution in the fastest time, and b) get the lowest $V_{final}$.

The winner will get a prize bestowed upon us courtesy of the Research School.



<!--chapter:end:14-FinalProject.Rmd-->

